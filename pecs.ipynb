{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xy(file, E_red, pH):\n",
    "    \"\"\"\n",
    "    This function reads the txt file containing the LSV or CV data,\n",
    "    extracts the relevant columns, and calculates the x and y values for plotting.\n",
    "    The function takes the file path, E_red, and pH as inputs.\n",
    "    It reads the file, skips the first 19 rows, and assigns column names.\n",
    "    The function then extracts the 'potential' and 'current' columns. \n",
    "    The x in the fuction is E vs RHE (V) and y is the current density.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the data file and skip the first 19 rows\n",
    "    df = pd.read_csv(file, sep = \"\\\\s+\", skiprows = 19, header = None)\n",
    "\n",
    "    # Assign column names\n",
    "    df.columns = [\"No\", \"time\", \"potential\", \"current\"]\n",
    "\n",
    "    # Calculate x and y values\n",
    "    x = df[\"potential\"] + E_red + (0.059 * pH)\n",
    "    y = df[\"current\"]/0.1979 \n",
    "\n",
    "    # return x, y values\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "This script calculates the x and y values for plotting LSV or CV data.\n",
    "It takes the file path, E_red, and pH as inputs.\n",
    "The script reads the file, skips the first 19 rows, and assigns column names.\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = str(input(\"Enter the main path: \")) # instead of input, you can directly define the path here \"D\\nam\\data\\20250411\"\n",
    "folders = os.listdir(main_path) # Lists all the folders in the main path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_reds, pHs = [], [] # Define empty lists to store E_red and pH values\n",
    "\n",
    "# Loop through each folder and get the E_red and pH values\n",
    "for f in folders:\n",
    "    # Go inside each folder and Ask the user for E_red and pH values for each folder\n",
    "    E_red, pH = float(input(f\"Enter the E_red value for {f} (Enter 0 if it is not needed for your calculation): \")), float(input(f\"Enter the pH value for {f} (Enter 0 if it is not needed for your calculation): \"))\n",
    "\n",
    "    # Once you enter the values, append them to the lists\n",
    "    E_reds.append(E_red)\n",
    "    pHs.append(pH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you dont want to view/save plots (Your main usecase for using these codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty dictionary to store the master data for LSV and CV\n",
    "lsv_master_dict = {}\n",
    "cv_master_dict = {}\n",
    "\n",
    "# loop through each folder and read the LSV and CV files, while taking the E_red and pH values into account for the respective folder\n",
    "for f, E_red, pH in zip(folders, E_reds, pHs):\n",
    "    # Get the LSV and CV files in the folder\n",
    "    # The glob module is used to find all the pathnames matching a specified pattern\n",
    "    lsv_files = glob.glob(os.path.join(main_path, f, \"*lsv*txt\"))\n",
    "    cv_files = glob.glob(os.path.join(main_path, f, \"*cv*txt\"))\n",
    "\n",
    "    combined_lsv_dict = {}\n",
    "    # Let us loop through the LSV files to read them one by one\n",
    "    for lsv_file in lsv_files:\n",
    "\n",
    "        # read the lsv file, and use our function to calculate x and y values (E vs RHE and current density)\n",
    "        # The function calculate_xy is defined above\n",
    "        x, y = calculate_xy(lsv_file, E_red, pH)\n",
    "\n",
    "        # Save individual output as a data frame and convert it into a CSV file\n",
    "        df = pd.DataFrame({'E_vs_RHE': x, 'Current_density': y})\n",
    "        df.to_csv(lsv_file.replace('.txt', '_output.csv'), index=False)\n",
    "\n",
    "        # Add to master dict\n",
    "        combined_lsv_dict[f\"{lsv_file.split('\\\\')[-1].split('.')[0]}_x\"] = x\n",
    "        combined_lsv_dict[f\"{lsv_file.split('\\\\')[-1].split('.')[0]}_y\"] = y\n",
    "\n",
    "        # Read the file name, remove the .txt in the file name and replace it with filename_x and filename_y for the columns of the master data\n",
    "        key_base = os.path.basename(lsv_file).replace('.txt', '')\n",
    "        lsv_master_dict[f\"{key_base}_x\"] = x\n",
    "        lsv_master_dict[f\"{key_base}_y\"] = y\n",
    "    \n",
    "    # Combine the LSV data into a single DataFrame\n",
    "    combined_lsv_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in combined_lsv_dict.items()]))\n",
    "    combined_lsv_df.to_csv(os.path.join(main_path, f, f\"{f}_combined_LSV.csv\"), index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    # Same procedure for the CV files\n",
    "    combined_cv_dict = {}\n",
    "    for cv_file in cv_files:\n",
    "        x, y = calculate_xy(cv_file, E_red, pH)\n",
    "\n",
    "        # Save individual output\n",
    "        df = pd.DataFrame({'E_vs_RHE': x, 'Current_density': y})\n",
    "        df.to_csv(cv_file.replace('.txt', '_output.csv'), index=False)\n",
    "\n",
    "        # Add to master dict\n",
    "        key_base = os.path.basename(cv_file).replace('.txt', '')\n",
    "        cv_master_dict[f\"{key_base}_x\"] = x\n",
    "        cv_master_dict[f\"{key_base}_y\"] = y\n",
    "\n",
    "        # combined cv dict\n",
    "        combined_cv_dict[f\"{cv_file.split('\\\\')[-1].split('.')[0]}_x\"] = x\n",
    "        combined_cv_dict[f\"{cv_file.split('\\\\')[-1].split('.')[0]}_y\"] = y\n",
    "\n",
    "    # Combine the CV data into a single DataFrame\n",
    "    combined_cv_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in combined_cv_dict.items()]))\n",
    "    combined_cv_df.to_csv(os.path.join(main_path, f\"{f}_combined_CV.csv\"), index=False)\n",
    "\n",
    "\n",
    "# Convert to DataFrames and save\n",
    "\n",
    "# Convert LSV master dictionary to DataFrame and save\n",
    "lsv_master_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in lsv_master_dict.items()]))\n",
    "lsv_master_df.to_csv(os.path.join(main_path, \"master_LSV.csv\"), index=False)\n",
    "\n",
    "# Convert CV master dictionary to DataFrame and save\n",
    "cv_master_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in cv_master_dict.items()]))\n",
    "cv_master_df.to_csv(os.path.join(main_path, \"master_CV.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to view/save the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsv_master_dict = {}\n",
    "cv_master_dict = {}\n",
    "\n",
    "for f, E_red, pH in zip(folders, E_reds, pHs):\n",
    "    lsv_files = glob.glob(os.path.join(main_path, f, \"*lsv*.txt\"))\n",
    "    cv_files = glob.glob(os.path.join(main_path, f, \"*cv*.txt\"))\n",
    "\n",
    "\n",
    "    combined_lsv_dict = {}\n",
    "    combined_cv_dict = {}\n",
    "    \n",
    "    for lsv_file in lsv_files:\n",
    "        x,y = calculate_xy(lsv_file, E_red, pH)\n",
    "        plt.plot(x, y, label=lsv_file.split('\\\\')[-1].split('.')[0])\n",
    "        plt.xlabel('E vs RHE (V)')\n",
    "        plt.ylabel('Current Density')\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1, 1), fontsize=8)\n",
    "        \n",
    "        df = pd.DataFrame({'E_vs_RHE': x, 'Current_density': y})\n",
    "        df.to_csv(lsv_file.replace('.txt', '_output.csv'), index=False)\n",
    "\n",
    "        key_base = os.path.basename(lsv_file).replace('.txt', '')\n",
    "        lsv_master_dict[f\"{key_base}_x\"] = x\n",
    "        lsv_master_dict[f\"{key_base}_y\"] = y\n",
    "\n",
    "        combined_lsv_dict[f\"{lsv_file.split('\\\\')[-1].split('.')[0]}_x\"] = x\n",
    "        combined_lsv_dict[f\"{lsv_file.split('\\\\')[-1].split('.')[0]}_y\"] = y\n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(f\"Plot for {f}, LSV\")\n",
    "    plt.savefig(os.path.join(main_path, f, \"lsv_plot.png\"), dpi=300)\n",
    "    plt.savefig(os.path.join(main_path, f, \"lsv_plot.pdf\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    combined_lsv_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in combined_lsv_dict.items()]))\n",
    "    combined_lsv_df.to_csv(os.path.join(main_path, f\"{f}_combined_LSV.csv\"), index=False)\n",
    "\n",
    "    \n",
    "    for cv_file in cv_files:\n",
    "        x,y = calculate_xy(cv_file, E_red, pH)\n",
    "\n",
    "        plt.plot(x, y, label=cv_file.split('\\\\')[-1].split('.')[0])\n",
    "        plt.xlabel('E vs RHE (V)')\n",
    "        plt.ylabel('Current Density')\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1, 1), fontsize=8)\n",
    "        \n",
    "        df = pd.DataFrame({'E_vs_RHE': x, 'Current_density': y})\n",
    "        df.to_csv(cv_file.replace('.txt', '_output.csv'), index=False)\n",
    "\n",
    "        key_base = os.path.basename(cv_file).replace('.txt', '')\n",
    "        cv_master_dict[f\"{key_base}_x\"] = x\n",
    "        cv_master_dict[f\"{key_base}_y\"] = y\n",
    "\n",
    "        combined_cv_dict[f\"{cv_file.split('\\\\')[-1].split('.')[0]}_x\"] = x\n",
    "        combined_cv_dict[f\"{cv_file.split('\\\\')[-1].split('.')[0]}_y\"] = y\n",
    "\n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(f\"Plot for {f}, CV\")\n",
    "    plt.savefig(os.path.join(main_path, f, \"cv_plot.png\"), dpi=300)\n",
    "    plt.savefig(os.path.join(main_path, f, \"cv_plot.pdf\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Combine the CV data into a single DataFrame\n",
    "    combined_cv_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in combined_cv_dict.items()]))\n",
    "    combined_cv_df.to_csv(os.path.join(main_path, f\"{f}_combined_CV.csv\"), index=False)\n",
    "\n",
    "\n",
    "# Convert to DataFrames and save\n",
    "lsv_master_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in lsv_master_dict.items()]))\n",
    "cv_master_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in cv_master_dict.items()]))\n",
    "\n",
    "lsv_master_df.to_csv(os.path.join(main_path, \"master_LSV.csv\"), index=False)\n",
    "cv_master_df.to_csv(os.path.join(main_path, \"master_CV.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
